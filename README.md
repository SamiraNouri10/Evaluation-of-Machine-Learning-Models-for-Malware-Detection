Welcome to the repository for the research paper "Comprehensive Evaluation of Machine Learning Models for Malware Detection across Diverse Datasets." This repository contains all the necessary code, data, and instructions to reproduce the results presented in the paper.

## Table of Contents

- [Overview](#overview)
- [Datasets](#datasets)
- [Models](#models)
- [Preprocessing Techniques](#preprocessing-techniques)
- [Experiments and Results](#experiments-and-results)
- [Installation](#installation)
- [Usage](#usage)
- [Contributing](#contributing)
- [Future Work](#future-work)
- [License](#license)

## Overview

The increasing reliance on the internet and mobile devices has exposed us to many cybersecurity threats. Traditional methods for detecting malware often fall short in accuracy and efficiency. Machine learning (ML) offers a promising alternative, enabling rapid and precise identification of malicious software. This project aims to evaluate the performance of 11 machine learning and deep learning models on nine publicly available malware datasets.

## Datasets

We evaluated the following nine publicly available datasets in our study:

1. **Malware Dataset**
2. **The Android Malware Dataset (Drebin)**
3. **CIC-MalMem-2022 Dataset**
4. **EMBER Dataset**
5. **IoT-23 Dataset**
6. **Malevis Dataset**
7. **UGRansomware Attacks Dataset**
8. **Malware Detection using Machine Learning Dataset**
9. **Ransomware Detection Dataset**

Detailed information on each dataset is included in this repository.

## Models

We evaluated the following machine learning and deep learning models:

1. K-Nearest Neighbors (KNN)
2. Support Vector Machines (SVM) - RBF, Linear, Polynomial
3. Convolutional Neural Networks (CNN)
4. Long Short-Term Memory (LSTM)
5. Random Forest (RF)
6. Gradient Boosting (GB)
7. Naive Bayes (NB)
8. Decision Tree (DT)
9. XGBoost (XGB)

Each model's implementation and hyperparameters are provided in this repository.

## Preprocessing Techniques

Effective preprocessing ensures the accuracy and consistency of the dataset, which is essential for building reliable machine learning models. Key preprocessing steps include:

1. Data Cleaning
2. Normalization and Scaling
3. Feature Extraction and Selection
4. Data Augmentation and Balancing

Detailed preprocessing steps for each dataset are included in this repository.

### Summary of Preprocessing Steps Across Different Datasets

| Dataset   | Preprocessing Steps                                                                                                             | Size        |
|-----------|----------------------------------------------------------------------------------------------------------------------------------|-------------|
| Dataset 1 | i) Feature selection via chi-square test for ML models, ii) Standardization and normalization                                    | 11,555KB    |
| Dataset 2 | i) Label encoding via LabelEncoder, ii) SMOTE for balancing, iii) Feature selection with Extra Trees for ML models              | 6,523KB     |
| Dataset 3 | i) Feature selection with Extra Trees for ML models, ii) Standardization and normalization                                       | 17,978KB    |
| Dataset 4 | i) Removal of unlabeled values, ii) Label encoding via LabelEncoder                                                              | 5,832,181KB |
| Dataset 5 | i) Binary classification setup, ii) PCA for feature selection in ML models, iii) Standardization and normalization               | 882,348KB   |
| Dataset 6 | i) Feature extraction with ResNet50 for ML models, ii) Data normalization for DL models                                          | 3,134,891KB |
| Dataset 7 | i) Deduplication, ii) Label encoding via LabelEncoder                                                                            | 9,790KB     |
| Dataset 8 | i) Removal of unlabeled features, ii) Handling missing values, iii) Label encoding via LabelEncoder                              | 170,100KB   |
| Dataset 9 | i) Deduplication, ii) Removal of unlabeled and missing values, iii) Label encoding via LabelEncoder                              | 7,500KB     |

## Experiments and Results

The evaluation of models was conducted using Azure Machine Learning Workspace. We used various performance metrics including accuracy, precision, recall, and F1 score. The comprehensive results are documented in this repository.

### Performance Comparison of Different Models on 9 Datasets

| Models/Datasets | Dataset 1 Accuracy | Dataset 1 F1 | Dataset 1 Recall | Dataset 1 Precision | Dataset 2 Accuracy | Dataset 2 F1 | Dataset 2 Recall | Dataset 2 Precision | Dataset 3 Accuracy | Dataset 3 F1 | Dataset 3 Recall | Dataset 3 Precision |
|-----------------|---------------------|--------------|------------------|---------------------|---------------------|--------------|------------------|---------------------|---------------------|--------------|------------------|---------------------|
| KNN             | 0.982               | 0.969        | 0.956            | 0.983               | 0.986               | 0.986        | 0.990            | 0.983               | 0.999               | 0.999        | 0.997            | 1.000               |
| SVM_rbf         | 0.979               | 0.964        | 0.951            | 0.979               | 0.984               | 0.983        | 0.978            | 0.989               | 0.998               | 0.998        | 0.998            | 0.999               |
| SVM_linear      | 0.973               | 0.953        | 0.941            | 0.968               | 0.980               | 0.980        | 0.980            | 0.979               | 0.998               | 0.998        | 0.997            | 0.999               |
| SVM_poly        | 0.979               | 0.964        | 0.949            | 0.980               | 0.975               | 0.975        | 0.959            | 0.991               | 0.998               | 0.998        | 0.997            | 0.999               |
| CNN             | 0.989               | 0.982        | 0.983            | 0.981               | 0.986               | 0.981        | 0.978            | 0.984               | 1.000               | 1.000        | 1.000            | 0.999               |
| LSTM            | 0.984               | 0.974        | 0.976            | 0.972               | 0.751               | 0.645        | 0.735            | 0.613               | 0.995               | 0.995        | 0.993            | 0.996               |
| Random Forest   | 0.984               | 0.972        | 0.958            | 0.988               | 0.990               | 0.990        | 0.986            | 0.994               | 0.999               | 0.999        | 0.998            | 1.000               |
| Gradient Boost  | 0.982               | 0.970        | 0.959            | 0.982               | 0.959               | 0.959        | 0.954            | 0.963               | 0.999               | 0.999        | 0.997            | 1.000               |
| Naive Bayes     | 0.918               | 0.836        | 0.741            | 0.980               | 0.757               | 0.803        | 0.986            | 0.677               | 0.991               | 0.991        | 0.994            | 0.987               |
| Decision Tree   | 0.975               | 0.957        | 0.933            | 0.984               | 0.979               | 0.979        | 0.981            | 0.977               | 0.998               | 0.998        | 0.997            | 1.000               |
| XGBoost         | 0.983               | 0.970        | 0.954            | 0.987               | 0.991               | 0.991        | 0.990            | 0.992               | 0.999               | 0.999        | 0.997            | 1.000               |

## Installation

To run the experiments locally, please follow these steps:

1. Clone the repository:
   ```sh
   git clone https://github.com/SamiraNouri10/Evaluation-of-Machine-Learning-Models-for-Malware-Detection.git
   cd Evaluation-of-Machine-Learning-Models-for-Malware-Detection
   ```

2. Create and activate a virtual environment:
   ```sh
   python -m venv venv
   source venv/bin/activate  # On Windows use `venv\Scripts\activate`
   ```

3. Install the required dependencies:
   ```sh
   pip install -r requirements.txt
   ```

4. Download and place the datasets in the `data` directory.

## Usage



To run the experiments, use the provided Jupyter notebooks in the `notebooks` directory. Each notebook is dedicated to a specific model or dataset.

Example:
```sh
jupyter notebook notebooks/KNN_Dataset1.ipynb
```

## Contributing

We welcome contributions to this project! If you would like to contribute, please follow these steps:

1. Fork the repository.
2. Create a new branch for your feature or bug fix.
3. Commit your changes and push your branch to GitHub.
4. Submit a pull request with a detailed description of your changes.

## Future Work

We are looking to expand this repository to include more datasets and models. Your inputs and updates are highly appreciated. If you have any suggestions or would like to contribute additional datasets or models, please open an issue or submit a pull request.

## License

This project is licensed under the MIT License. See the LICENSE file for more details.

## Acknowledgments

We thank all the researchers and developers whose work contributed to this project. Special thanks to the University of Aberdeen for supporting this research.

For any questions or issues, please open an issue on GitHub or contact us directly.

---
